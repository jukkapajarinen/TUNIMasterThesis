@misc{istqb_glossary_nodate,
  title = {ISTQB Glossary},
  url = {https://glossary.istqb.org/en},
  year = {2019}
}

@misc{iso_9126-1_2001,
  title = {{ISO}/{IEC} 9126-1:2001},
  shorttitle = {{ISO}/{IEC} 9126-1},
  url = {http://www.iso.org/cms/render/live/en/sites/isoorg/contents/data/standard/02/27/22749.html},
  abstract = {Software engineering — Product quality — Part 1: Quality model},
  language = {en},
  journal = {ISO},
  author = {ISO:9126-1},
  year = {2001}
}

@article{pesonen_verkkoteorian_nodate,
  title = {{VERKKOTEORIAN} {ALKEITA}},
  language = {fi},
  author = {Pesonen, Martti E},
  pages = {38}
}

@book{pinkster_successful_2004,
  address = {Berlin Heidelberg},
  title = {Successful {Test} {Management}: {An} {Integral} {Approach}},
  isbn = {978-3-540-22822-6},
  shorttitle = {Successful {Test} {Management}},
  url = {https://www.springer.com/gp/book/9783540228226},
  abstract = {At a time when information systems are becoming ever more complex and quality to market and time to market are critical for many companies, a structured test process is essential. Even more important is a structured test management process to keep testing under control. Nowadays a test manager must have extensive knowledge of and experience with project management, risk assessment, team building, and, process improvement. Based on their long-term industry experience, Pinkster and her coauthors describe a holistic approach to test management that combines test methods, test management, risk assessment and stakeholder management into one integral process, giving test managers, test coordinators, IT project managers, and QA managers a competitive edge in environments where there are numerous unstructured requirements, tough testing schedules and limited resources. This book should be in every test manager's backpack!},
  language = {en},
  publisher = {Springer-Verlag},
  author = {Pinkster, Iris and Burgt, Bob van de and Janssen, Dennis and Veenendaal, Erik van},
  year = {2004}
}

@book{bang-jensen_digraphs:_2009,
  address = {London},
  edition = {2},
  series = {Springer {Monographs} in {Mathematics}},
  title = {Digraphs: {Theory}, {Algorithms} and {Applications}},
  isbn = {978-1-84800-997-4},
  shorttitle = {Digraphs},
  url = {https://www.springer.com/gp/book/9781848009974},
  abstract = {The theory of directed graphs has developed enormously over recent decades, yet this book (first published in 2000) remains the only book to cover more than a small fraction of the results. New research in the field has made a second edition a necessity. Substantially revised, reorganised and updated, the book now comprises eighteen chapters, carefully arranged in a straightforward and logical manner, with many new results and open problems. As well as covering the theoretical aspects of the subject, with detailed proofs of many important results, the authors present a number of algorithms, and whole chapters are devoted to topics such as branchings, feedback arc and vertex sets, connectivity augmentations, sparse subdigraphs with prescribed connectivity, and also packing, covering and decompositions of digraphs. Throughout the book, there is a strong focus on applications which include quantum mechanics, bioinformatics, embedded computing, and the travelling salesman problem. Detailed indices and topic-oriented chapters ease navigation, and more than 650 exercises, 170 figures and 150 open problems are included to help immerse the reader in all aspects of the subject. Digraphs is an essential, comprehensive reference for undergraduate and graduate students, and researchers in mathematics, operations research and computer science. It will also prove invaluable to specialists in related areas, such as meteorology, physics and computational biology. Jørgen Bang-Jensen is a Professor in the Department of Mathematics and Computer Science at the University of Southern Denmark, Odense, Denmark. Gregory Gutin is Professor of Computer Science at Royal Holloway College, University of London, UK.},
  language = {en},
  publisher = {Springer-Verlag},
  author = {Bang-Jensen, Jørgen and Gutin, Gregory Z.},
  year = {2009}
}

@misc{noauthor_tietorakenteet_nodate,
  title = {Tietorakenteet ja algoritmit: {Luku} 13 {Painotettu} verkko},
  url = {http://www.cs.uku.fi/~hmayra/kurssit/tra/luku13.html}
}

@misc{noauthor_test_nodate,
  title = {Test {Prioritization} or {Test} {Case} {Prioritization} {\textbar}{Professionalqa}.com},
  url = {http://www.professionalqa.com/test-prioritization}
}

@misc{noauthor_test_nodate-1,
  title = {A {Test} {Case} {Prioritization} {Method} with {Practical} {Weight} {Factors}},
  url = {https://scialert.net/abstract/?doi=jse.2010.193.214},
  abstract = {Abstract: A Test Case Prioritization Method with Practical Weight Factors},
  doi = {10.3923/jse.2010.193.214}
}

@misc{noauthor_principles_nodate,
  title = {Principles of {Automated} {Testing}},
  url = {http://www.lihaoyi.com/post/PrinciplesofAutomatedTesting.html}
}

@misc{noauthor_chapter_nodate,
  title = {Chapter 10: {MoSCoW} {Prioritisation}},
  url = {https://www.agilebusiness.org/page/ProjectFramework_10_MoSCoWPrioritisation}
}

@inproceedings{ahmad_fuzzy_moscow:_2017,
  address = {Kerala State,Kannur, India},
  title = {Fuzzy\_MoSCoW: {A} fuzzy based {MoSCoW} method for the prioritization of software requirements},
  isbn = {978-1-5090-6106-8},
  shorttitle = {Fuzzy\_MoSCoW},
  url = {http://ieeexplore.ieee.org/document/8342602/},
  doi = {10.1109/ICICICT1.2017.8342602},
  booktitle = {2017 {International} {Conference} on {Intelligent} {Computing}, {Instrumentation} and {Control} {Technologies} ({ICICICT})},
  publisher = {IEEE},
  author = {Ahmad, Khadija Sania and Ahmad, Nazia and Tahir, Hina and Khan, Shaista},
  month = jul,
  year = {2017},
  pages = {433--437}
}

@misc{noauthor_20_nodate,
  title = {20 {Useful} {Test} {Cases} for testing {User} {Interfaces}},
  url = {https://smartbear.com/blog/develop/20-useful-test-cases-for-testing-user-interfaces/},
  abstract = {When testing user interfaces, it is easy to overlook test cases that would be helpful for a more thoroughly tested solution. This newsletter identifies 20 test cases that might be considered when testing user interfaces.20 Useful Test Cases for testing User InterfacesRequired Fields - If the scre...},
  journal = {SmartBear.com}
}

@article{burguillo_heuristic-driven_2002,
  title = {Heuristic-driven {Techniques} for {Test} {Case} {Selection}},
  volume = {66},
  doi = {10.1016/S1571-0661(04)80403-1},
  abstract = {We propose an approach to testing that combines formal methods with practical criteria, close to the testing engineer's experience. It can be seen as a framework to evaluate and select test suites using formal methods, assisted by informal heuristics. We also introduce the formalism of enriched transition systems to store information obtained during the testing phase, and to adapt classical test generation techniques to take advantage of the possibilities of the new formalism.},
  journal = {Electr. Notes Theor. Comput. Sci.},
  author = {Burguillo, Juan and Llamas Nistal, Martín and Fernández Iglesias, Manuel José and Robles, Tomas},
  month = dec,
  year = {2002},
  pages = {50--65}
}

@article{kankare_ankkuroitu_nodate,
  title = {Ankkuroitu tutkimus - grounded theory},
  language = {fi},
  author = {Kankare, Ronja and Oinonen, Riika},
  pages = {4}
}

@misc{noauthor_robot_nodate,
  title = {Robot {Framework} {User} {Guide}},
  url = {https://robotframework.org/robotframework/3.1.2/RobotFrameworkUserGuide.html}
}

@misc{klarck_how-to-write-good-test-cases_2019,
  title = {How to write good test cases using Robot Framework},
  author = {Klärck, Pekka},
  year = {2019},
  url = {https://github.com/robotframework/HowToWriteGoodTestCases/blob/master/HowToWriteGoodTestCases.rst}
}

@inproceedings{zhang_test_2007,
  title = {Test {Case} {Prioritization} {Based} on {Varying} {Testing} {Requirement} {Priorities} and {Test} {Case} {Costs}},
  doi = {10.1109/QSIC.2007.4385476},
  abstract = {Test case prioritization is an effective and practical technique in regression testing. It schedules test cases in order of precedence that increases their ability to meet some performance goals, such as code coverage, rate of fault detection. In previous work, the test case prioritization techniques and metrics usually assumed that testing requirement priorities and test case costs are uniform. In this paper, basing on varying testing requirement priorities and test case costs, we present a new, general test case prioritization technique and an associated metric. The case study illustrates that the rate of "units-oftesting-requirement-priority-satisfied- per-unit-test-case-cost" can be increased, and then the testing quality and customer satisfaction can be improved.},
  booktitle = {Seventh {International} {Conference} on {Quality} {Software} ({QSIC} 2007)},
  author = {Zhang, X. and Nie, C. and Xu, B. and Qu, B.},
  month = oct,
  year = {2007},
  keywords = {Computer science, Costs, Customer satisfaction, Fault detection, Feedback, Life testing, Processor scheduling, Programming, Software quality, Software testing, code coverage, customer satisfaction, fault detection, program testing, regression testing, software reliability, software testing, test case costs, test case prioritization, testing quality, testing requirement priorities, varying testing requirement priorities},
  pages = {15--24}
}

@inproceedings{nawar_multi-heuristic_2014,
  series = {Lecture {Notes} in {Computer} {Science}},
  title = {Multi-heuristic {Based} {Algorithm} for {Test} {Case} {Prioritization}},
  isbn = {978-3-319-09156-3},
  abstract = {Regression testing is the process of retesting the software after it has been modified and ensuring that there is no new errors have been introduced in the software due to these modifications. As the size of the software projects increases, the regression testing became a very costly process, so the need of detecting the faults in the software project as fast as possible became more and more important. Test case prioritization arranges test cases for execution to increase the probability of early fault detection during the regression testing. In this paper, three simple test case prioritization heuristics are presented, where every heuristic calculates the average number faults found per each test case. The three heuristics are combined together to develop a multi-heuristic based algorithm that arrange test cases based on their priorities using the scores obtained from the three heuristics. The effectiveness of the three heuristics and the multi-heuristic based algorithm are illustrated with the help of APFD (Average Percentage Faults Detected) metric. The main aim of this paper is to show how using simple heuristics for test cases prioritization would help in error early detection during regression testing, and to show how the proposed multi-heuristic based algorithm has significant increase in terms of APFD even if the algorithm is using simple heuristics.},
  language = {en},
  booktitle = {Computational {Science} and {Its} {Applications} – {ICCSA} 2014},
  publisher = {Springer International Publishing},
  author = {Nawar, Michael N. and Ragheb, Moheb M.},
  editor = {Murgante, Beniamino and Misra, Sanjay and Rocha, Ana Maria A. C. and Torre, Carmelo and Rocha, Jorge Gustavo and Falcão, Maria Irene and Taniar, David and Apduhan, Bernady O. and Gervasi, Osvaldo},
  year = {2014},
  keywords = {Mutation Fault, Prioritization Technique, Software Project, Test Case Prioritization, Test Suite},
  pages = {449--460}
}